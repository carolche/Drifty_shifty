{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4f6317",
   "metadata": {},
   "source": [
    "Title: FocusStackerDedrifter\n",
    "AUTHOR: Caroline Berthebaud Cheung\n",
    "DATE: 2022/05/23 (YY/MM/DD)\n",
    "\n",
    "[] =  FocusStackerDedrifter(input_dir, output_dir_fs, output_dir_ds, output_dir, output_format, fs=True, image_range_\n",
    "      fs=True, ds=True, image_range_ds=True, shift_data=True, pad=True, overwrite=True, parallel=True, crop=True)\n",
    "\n",
    "    This script is used as a pipeline to run FocusStacker, Drifty_Shifty, and crop_aligned_images sequentially in\n",
    "    order to merge slices of an image taken at different focal points into one focused image, to dedrift and align the\n",
    "    images, and then to crop and retain only the parts of the images that are visible in every single frame. This\n",
    "    script reads images from path='input_dir', focus stacks the images, and saves them into an output directory\n",
    "    (output_dir_fs). It then dedrifts these images and saves them into another output directory (output_dir_ds). Since\n",
    "    the dedrifting process will create a black border around the images, it may be removed using the\n",
    "    crop_aligned_images function, which takes the images in the 'output_dir_ds' directory as input, removes the black\n",
    "    border as well as parts of the images that are not in every single frame, and then saves the cropped images in the\n",
    "    final output directory (output_dir). All of the edited images will be saved as the given output format\n",
    "    (output_format ie. png or tif(f)).\n",
    "\n",
    "    To be clear, the input and output directories for the three different processes (FocusStacker, Drifty_Shifty,\n",
    "    crop_aligned_images) are as follows:\n",
    "    1. FocusStacker input directory = input_dir\n",
    "    2. FocusStacker output directory = output_dir_fs\n",
    "    3. Drifty_Shifty input directory = output_dir_fs\n",
    "    4. Drifty_Shifty output directory = output_dir_ds\n",
    "    5. crop_aligned_images input directory = output_dir_ds\n",
    "    6. crop_aligned_images output directory = output_dir\n",
    "\n",
    "    This pipeline takes 5 required inputs (input_dir, output_dir_fs, output_dir_ds, output_dir, output_format) and\n",
    "    9 optional parameters (image_range_fs, fs, ds, image_range_ds, shift_data, pad, overwrite, parallel, crop) which\n",
    "    are all True by default.\n",
    "    \n",
    "    If you don't want to convert all of your images in your folder, then input a tuple of\n",
    "    integers, bracketed and separated by a comma, as the image_range to denote the start and the end of the images to\n",
    "    be converted.\n",
    "    \n",
    "    If you want to just perform FocusStacker, then input ds=False, and if you wish to perform only\n",
    "    Drifty_Shifty, then input fs=False.\n",
    "\n",
    "    By default, \"shift_data\" is set as True which means that the function calc_shift will be called and a\n",
    "    shift array will be calculated. However, if there is already a calculated shift array (saved as\n",
    "    \"shift_arrays.npz\" file), then please move this file into \"output_dir_fs\" and input the file name as the\n",
    "    \"shift_data\" argument.\n",
    "\n",
    "    If you want to just calculate the shift array and not dedrift the images, then set pad=False.\n",
    "\n",
    "    By default, the variable input \"overwrite\" is set to True, but can be changed to False. This will save subsequent\n",
    "    files with the same base name with the addition of sequential numbers at the end.\n",
    "\n",
    "    User can also define whether to run the functions in parallel (via joblib) or not, denoted here as\n",
    "    \"parallel\", which by default is True but can be set to False.\n",
    "\n",
    "    Finally, by default, the dedrifted/aligned images will be cropped to remove the black padding created by the\n",
    "    dedrifting process and to retain only the parts of the images that are visible in every single frame (via the\n",
    "    crop_aligned_images function). But if crop is set to False, this function will not be called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b38b53",
   "metadata": {},
   "source": [
    "# Import all the dependencies/libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65093a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from joblib import Parallel, delayed\n",
    "from timeit import default_timer as timer\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import scipy.fft as fft\n",
    "from iteration_utilities import deepflatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd7c6bf",
   "metadata": {},
   "source": [
    "# All the functions for FocusStacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa034d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_laplacian_pyramid(img, N):\n",
    "    \"\"\"\n",
    "    returns N-level Laplacian Pyramid of input image as a list\n",
    "    @input: image\n",
    "    @output: - Laplacian Pyramid: list of N images containing laplacian pyramids from level 0 to level N\n",
    "             - Gaussian Pyramid: list of N images containing gaussian pyramids from level 0 to level N\n",
    "    \"\"\"\n",
    "    # current level image\n",
    "    curr_img = img\n",
    "\n",
    "    lap_pyramids = []\n",
    "    gaussian_pyramids = [curr_img, ]\n",
    "\n",
    "    # for N level\n",
    "    for i in range(N):\n",
    "        down = cv2.pyrDown(curr_img)\n",
    "        gaussian_pyramids.append(down)\n",
    "        up = cv2.pyrUp(down, dstsize=(curr_img.shape[1], curr_img.shape[0]))\n",
    "        lap = curr_img - up.astype('int16')  # NOTE: BE SURE to use int16 instead of cv2.subtract,\n",
    "        #       which cv2 will clip value to 0-255, here we want\n",
    "        #       arbitratry integeter value.\n",
    "        lap_pyramids.append(lap)\n",
    "        curr_img = down\n",
    "        # top level laplacian be a gaussian downsampled\n",
    "        if i == N - 1:\n",
    "            lap_pyramids.append(curr_img)\n",
    "\n",
    "    return lap_pyramids\n",
    "\n",
    "def get_probabilities(gray_image):\n",
    "    levels, counts = np.unique(gray_image.astype(np.uint8), return_counts=True)\n",
    "    probabilities = np.zeros((256,), dtype=np.float64)\n",
    "    probabilities[levels] = counts.astype(np.float64) / counts.sum()\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def _area_entropy(area, probabilities):\n",
    "    levels = area.flatten()\n",
    "    return -1. * (levels * np.log(probabilities[levels])).sum()\n",
    "\n",
    "\n",
    "def entropy(image, kernel_size):\n",
    "    probabilities = get_probabilities(image)\n",
    "    pad_amount = int((kernel_size - 1) / 2)\n",
    "    padded_image = cv2.copyMakeBorder(image, pad_amount, pad_amount, pad_amount, pad_amount, cv2.BORDER_REFLECT101)\n",
    "    entropies = np.zeros(image.shape[:2], dtype=np.float64)\n",
    "    offset = np.arange(-pad_amount, pad_amount + 1)\n",
    "    for row in range(entropies.shape[0]):\n",
    "        for column in range(entropies.shape[1]):\n",
    "            area = padded_image[row + pad_amount + offset[:, np.newaxis], column + pad_amount + offset]\n",
    "            entropies[row, column] = _area_entropy(area, probabilities)\n",
    "\n",
    "    return entropies\n",
    "\n",
    "\n",
    "def _area_deviation(area):\n",
    "    average = np.average(area).astype(np.float64)\n",
    "    return np.square(area - average).sum() / area.size\n",
    "\n",
    "\n",
    "# calculates the D: Deviation for every pixel locations\n",
    "# Source: https://github.com/sjawhar/focus-stacking/blob/master/focus_stack/pyramid.py - Line 108-122\n",
    "def deviation(image, kernel_size):\n",
    "    pad_amount = int((kernel_size - 1) / 2)\n",
    "    padded_image = cv2.copyMakeBorder(image, pad_amount, pad_amount, pad_amount, pad_amount, cv2.BORDER_REFLECT101)\n",
    "    deviations = np.zeros(image.shape[:2], dtype=np.float64)\n",
    "    offset = np.arange(-pad_amount, pad_amount + 1)\n",
    "    for row in range(deviations.shape[0]):\n",
    "        for column in range(deviations.shape[1]):\n",
    "            area = padded_image[row + pad_amount + offset[:, np.newaxis], column + pad_amount + offset]\n",
    "            deviations[row, column] = _area_deviation(area)\n",
    "\n",
    "    return deviations\n",
    "\n",
    "\n",
    "def generating_kernel(a):\n",
    "    kernel = np.array([0.25 - a / 2.0, 0.25, a, 0.25, 0.25 - a / 2.0])\n",
    "    return np.outer(kernel, kernel)\n",
    "\n",
    "\n",
    "def convolve(image, kernel=generating_kernel(0.4)):\n",
    "    return cv2.filter2D(src=image.astype(np.float64), ddepth=-1, kernel=np.flip(kernel))\n",
    "\n",
    "\n",
    "# calculated RE: regional energy for every pixel locations\n",
    "# Source: https://github.com/sjawhar/focus-stacking/blob/master/focus_stack/pyramid.py - Line 167-169\n",
    "def region_energy(laplacian):\n",
    "    return convolve(np.square(laplacian))\n",
    "\n",
    "\n",
    "#focus-stacking (laplacian pyramid fusion method)\n",
    "def lap_focus_stacking(images, N=5, kernel_size=5):\n",
    "    \"\"\"\n",
    "    achieves the functionality of focus stacking using Laplacian Pyramid Fusion described \n",
    "        in Wang and Chang's 2011 paper (regional fusion)\n",
    "    @input: images - array of images\n",
    "            N      - Depth of Laplacian Pyramid, default is 5\n",
    "            kernel_size - integer represents the side length of Gaussian kernel, default is 5\n",
    "    @output: single image that stacked the depth of fields of all images\n",
    "    \"\"\"\n",
    "\n",
    "    # 1- Generate array of Laplacian pyramids\n",
    "    list_lap_pyramids = np.array([get_laplacian_pyramid(img, N)[:-1] for img in images], dtype=object)\n",
    "\n",
    "    LP_f = []\n",
    "\n",
    "\n",
    "    # 2 - Regional fusion using these Laplacian pyramids\n",
    "    # fuse level = N laplacian pyramid, D=deviation, E=entropy\n",
    "    D_N = np.array([deviation(lap, kernel_size) for lap in list_lap_pyramids[:, -1]])\n",
    "    E_N = np.array([entropy(lap, kernel_size) for lap in list_lap_pyramids[:, -1]])\n",
    "\n",
    "    # 2.1 - init level N fusion canvas\n",
    "    LP_N = np.zeros(list_lap_pyramids[0, -1].shape)\n",
    "    for m in range(LP_N.shape[0]):\n",
    "        for n in range(LP_N.shape[1]):\n",
    "            D_max_idx = np.argmax(D_N[:, m, n])\n",
    "            E_max_idx = np.argmax(E_N[:, m, n])\n",
    "            D_min_idx = np.argmin(D_N[:, m, n])\n",
    "            E_min_idx = np.argmin(E_N[:, m, n])\n",
    "            # if the image maximizes BOTH the deviation and entropy, use the pixel from that image\n",
    "            if D_max_idx == E_max_idx:\n",
    "                LP_N[m, n] = list_lap_pyramids[D_max_idx, -1][m, n]\n",
    "            # if the image minimizes BOTH the deviation and entropy, use the pixel from that image\n",
    "            elif D_min_idx == E_min_idx: \n",
    "                LP_N[m, n] = list_lap_pyramids[D_min_idx, -1][m, n]\n",
    "            # else average across all images\n",
    "            else:\n",
    "                for k in range(list_lap_pyramids.shape[0]):\n",
    "                    LP_N[m, n] += list_lap_pyramids[k, -1][m, n]\n",
    "                LP_N[m, n] /= list_lap_pyramids.shape[0]\n",
    "\n",
    "    LP_f.append(LP_N)\n",
    "\n",
    "    # 2.2 - Fusion other levels of Laplacian pyramid (N-1 to 0)\n",
    "    for l in reversed(range(0, N-1)):\n",
    "        # level l final laplacian canvas\n",
    "        LP_l = np.zeros(list_lap_pyramids[0, l].shape)\n",
    "\n",
    "        # region energy map for level l\n",
    "        RE_l = np.array([region_energy(lap) for lap in list_lap_pyramids[:, l]], dtype=object)\n",
    "\n",
    "        for m in range(LP_l.shape[0]):\n",
    "            for n in range(LP_l.shape[1]):\n",
    "                RE_max_idx = np.argmax(RE_l[:, m, n])\n",
    "                LP_l[m, n] = list_lap_pyramids[RE_max_idx, l][m, n]\n",
    "\n",
    "        LP_f.append(LP_l)\n",
    "\n",
    "    LP_f = np.array(LP_f, dtype=object)\n",
    "    LP_f = np.flip(LP_f)\n",
    "\n",
    "\n",
    "    # 3 - time to reconstruct final laplacian pyramid(LP_f) back to original image!\n",
    "    # get the top-level of the gaussian pyramid\n",
    "    for img in images:\n",
    "        base = get_laplacian_pyramid(img, N)[-1]\n",
    "    fused_img = cv2.pyrUp(base, dstsize=(LP_f[-1].shape[1], LP_f[-1].shape[0])).astype(np.float64)\n",
    "\n",
    "    for i in reversed(range(N)):\n",
    "        # combine with laplacian pyramid at the level\n",
    "        fused_img += LP_f[i]\n",
    "        if i != 0:\n",
    "            fused_img = cv2.pyrUp(fused_img, dstsize=(LP_f[i-1].shape[1], LP_f[i-1].shape[0]))\n",
    "\n",
    "    return fused_img\n",
    "\n",
    "\n",
    "# Recreates the stacked image and saves it into output_dir\n",
    "def merged_focus(group, output_dir_fs, output_format, overwrite=True):\n",
    "\n",
    "    # 1 - load images (in GRAY)\n",
    "    image = [cv2.imread(g) for g in group]\n",
    "    if image[0].shape[2] == 3:\n",
    "        images = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in image])\n",
    "    else:\n",
    "        images = np.array([img for img in image])\n",
    "\n",
    "    # defines the base name in order to name the files correctly\n",
    "    z = group[0].rfind('z')\n",
    "    names = [g[:z] for g in group][0]\n",
    "\n",
    "    # check the filenames are valid\n",
    "    if any([image is None for image in images]):\n",
    "        raise RuntimeError(\"Cannot load one or more input files.\")\n",
    "\n",
    "    # 2 - focus stacking by first creating fused image as RGB image\n",
    "    RGB_images = np.array([img for img in images])\n",
    "    canvas = np.array([lap_focus_stacking(RGB_images[:, :, :])])\n",
    "    canvas = np.moveaxis(canvas, 0, -1)\n",
    "\n",
    "    # 3 - write to file (grayscale)\n",
    "    if overwrite == False:\n",
    "        a = glob.glob(os.path.join(output_dir_fs, f\"{names}_merged.{output_format}\"))\n",
    "        b = len(a)\n",
    "        if output_format.lower() == 'png':\n",
    "            if b == 0:\n",
    "                cv2.imwrite(os.path.join(output_dir_fs, f'{names}_merged.{output_format}'), canvas)\n",
    "            elif b == 1:\n",
    "                cv2.imwrite(os.path.join(output_dir_fs, f'{names}_merged1.{output_format}'), canvas)\n",
    "            else:\n",
    "                cv2.imwrite(os.path.join(output_dir_fs, f'{names}_merged{b}.{output_format}'), canvas)\n",
    "        else:\n",
    "            canvas2 = cv2.normalize(src=canvas, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "            if b == 0:\n",
    "                cv2.imwrite(os.path.join(output_dir_fs, f'{names}_merged.{output_format}'), canvas2)\n",
    "            elif b == 1:\n",
    "                cv2.imwrite(os.path.join(output_dir_fs, f'{names}_merged1.{output_format}'), canvas2)\n",
    "            else:\n",
    "                cv2.imwrite(os.path.join(output_dir_fs, f'{names}_merged{b}.{output_format}'), canvas2)\n",
    "    else:\n",
    "        if output_format.lower() == 'png':\n",
    "            cv2.imwrite(os.path.join(output_dir_fs, f'{names}_merged.{output_format}'), canvas)\n",
    "        else:\n",
    "            canvas2 = cv2.normalize(src=canvas, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "            cv2.imwrite(os.path.join(output_dir_fs, f'{names}_merged.{output_format}'), canvas2)\n",
    "\n",
    "    return None\n",
    "\n",
    "def FocusStacker(input_dir, output_dir_fs, output_format, parallel=True, image_range_fs=True, overwrite=True):\n",
    "\n",
    "    start = timer()\n",
    "    print('start merging')\n",
    "\n",
    "    # current working dir\n",
    "    cwd = os.curdir\n",
    "\n",
    "    # change working dir to image directory\n",
    "    os.chdir(input_dir)\n",
    "\n",
    "    # These are all the accepted types of extensions\n",
    "    expected_ext = ['png', 'tif', 'tiff']\n",
    "\n",
    "    # sorting and grouping images according to the base name and the number of slices (z)\n",
    "    image_files = sorted(os.listdir(input_dir))\n",
    "    file_names = [img for img in image_files if img.split(\".\")[-1].lower() in expected_ext and img[0].isalnum()]\n",
    "\n",
    "    # If you don't want to convert all of your images in your folder, then input a tuple of integers as image_range.\n",
    "    # Input 2 integers (bracketed and separated by a comma) to denote the start and the end of the images to be\n",
    "    # converted. If you do not input exactly 2 integers, an error will be raised. If image_range is True,\n",
    "    # all the files in the folder will be passed into the function.\n",
    "    if image_range_fs != True:\n",
    "        if len(image_range_fs)!=2:\n",
    "            sys.exit(\"image_range doesn't exist. Please input a tuple of two values.\")\n",
    "        else:\n",
    "            file_names = file_names[image_range_fs[0]:image_range_fs[1]]\n",
    "\n",
    "    z = file_names[0].rfind('z')\n",
    "    groups = [list(g) for _, g in itertools.groupby(sorted(file_names), lambda x: x[0:z])]\n",
    "\n",
    "    # determines how many slices (z - images with different focus) in each group\n",
    "    for group in groups:\n",
    "        num_of_zplane_images = len(group)\n",
    "\n",
    "    # input sanity checks\n",
    "    num_files = len(file_names)\n",
    "    assert num_files > 1, \"Provide at least 2 images.\"\n",
    "\n",
    "    # determines the number of files already in output directory\n",
    "    output_files = os.listdir(output_dir_fs)\n",
    "    if len(output_files) != (0 or len(file_names)/num_of_zplane_images):\n",
    "        output_files2 = [output_file.split('_merged')[0] for output_file in output_files]\n",
    "        file_names2 = [f for f in file_names if f[0:z] not in output_files2]\n",
    "        groups = [list(g) for _, g in itertools.groupby(sorted(file_names2), lambda x: x[0:z])]\n",
    "\n",
    "\n",
    "    # If you want to run the main focus stacking function, merged_focus, serially which would be slower\n",
    "    if parallel == False:\n",
    "        [merged_focus(group, output_dir_fs, output_format, overwrite) for group in groups]\n",
    "    else:\n",
    "        # run the main focus stacking function, merged_focus, in parallel with joblib\n",
    "        Parallel(n_jobs=-1)(delayed(merged_focus)(group, output_dir_fs, output_format, overwrite) for group in groups)\n",
    "\n",
    "    # change working dir back to original working directory\n",
    "    os.chdir(cwd)\n",
    "    end = timer()\n",
    "    print(f'elasped time {end-start}, Focus Stacking successful')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e22a1",
   "metadata": {},
   "source": [
    "# All the functions for Drifty_shifty (dedrifter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref(images):\n",
    "\n",
    "    # Get and process reference frame (first one in the sequence)\n",
    "    frameref = cv2.imread(images[0])\n",
    "    if frameref.shape[2] == 3:\n",
    "        frameref = cv2.cvtColor(frameref, cv2.COLOR_BGR2GRAY)\n",
    "    fft_ref = fft.fft2(frameref)\n",
    "\n",
    "    vidHeight = frameref.shape[1]\n",
    "    vidWidth = frameref.shape[0]  # The blank variable here gets rid of extra padding - we didn't do this in python!!\n",
    "    centery = (vidHeight / 2) + 1\n",
    "    centerx = (vidWidth / 2) + 1\n",
    "\n",
    "    return fft_ref, vidHeight, vidWidth, centery, centerx\n",
    "\n",
    "\n",
    "# this function performs fourier transformation for each image and returns the maximum x and y indices\n",
    "def calc_shift(images, fft_ref):\n",
    "\n",
    "    img = cv2.imread(images)\n",
    "    if img.shape[2] == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate fourier transformation of each image\n",
    "    fft_frame = fft.fft2(img)\n",
    "\n",
    "    # vector multiplication of the fourier-transformed image reference with the\n",
    "    # complex conjugate array of each fourier-transformed image\n",
    "    prod = fft_ref * np.conjugate(fft_frame)\n",
    "\n",
    "    # get inverse fourier transformation of the product\n",
    "    # need to get the \"real\" numbers and not the imaginary numbers\n",
    "    cc = (fft.ifft2(prod)).real\n",
    "\n",
    "    # 'fftshift' moves corners to center, 'max()' gives largest element in the whole array, and\n",
    "    # 'where' returns indices of that point\n",
    "    maxYX = np.where(fft.fftshift(cc) == np.max(cc))\n",
    "\n",
    "    return maxYX\n",
    "\n",
    "\n",
    "# this function then takes the maximum x and y indices to calculate the x-y shift array\n",
    "def calc_shift2(images, maxYX, vidHeight, vidWidth, centery, centerx):\n",
    "\n",
    "    nFrames = len(images)\n",
    "\n",
    "    shifty = np.zeros((nFrames,))\n",
    "    shiftx = np.zeros((nFrames,))\n",
    "\n",
    "    maxYX2 = list(deepflatten(maxYX))\n",
    "    maxY = maxYX2[::2]\n",
    "    maxX = maxYX2[1::2]\n",
    "\n",
    "    i=0\n",
    "    for i in range(nFrames):\n",
    "\n",
    "        shifty[i] = maxY[i] - centery\n",
    "        shiftx[i] = maxX[i] - centerx\n",
    "\n",
    "        # Previous version didn't subtract center point here\n",
    "        if i > 0:  # Checks to see if there is an ambiguity problem with FFT because of the periodic boundary in FFT\n",
    "            if np.abs(shifty[i] - shifty[i - 1]) > vidHeight / 2:\n",
    "                shifty[i] = shifty[i] - np.sign(shifty[i] - shifty[i - 1]) * vidHeight\n",
    "\n",
    "            if np.abs(shiftx[i] - shiftx[i - 1]) > vidWidth / 2:\n",
    "                shiftx[i] = shiftx[i] - np.sign(shiftx[i] - shiftx[i - 1]) * vidWidth\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "    return shifty, shiftx\n",
    "\n",
    "\n",
    "# Step 2: Pads and defrifts images\n",
    "\n",
    "# This function is the core function and actually pads, centers, and dedrifts the images according to the calculated\n",
    "# shift data. It will take the shift array saved as an .npz file in the 'input_dir' and dedrift the images accordingly.\n",
    "def pad_images(images, shift_arrays, output_dir, output_format, overwrite=True):\n",
    "\n",
    "    # this will load the shift_data from the calc_shift function\n",
    "    with np.load(shift_arrays) as data:\n",
    "        shiftx = data['x']\n",
    "        shifty = data['y']\n",
    "\n",
    "    # number of images\n",
    "    nFrames = len(images)\n",
    "\n",
    "    # Get Height & Width of reference image (first one in the sequence)\n",
    "    frameref = cv2.imread(images[0])\n",
    "    if frameref.shape[2] == 3:\n",
    "        frameref = cv2.cvtColor(frameref, cv2.COLOR_BGR2GRAY)\n",
    "    frameref = frameref.astype(dtype='uint8')\n",
    "    vidHeight, vidWidth = frameref.shape[0:2]\n",
    "\n",
    "    # Pad the images. Use first image as \"center\"\n",
    "    newsizey = round(2 * np.max(np.abs(shifty)) + vidHeight)\n",
    "    newsizex = round(2 * np.max(np.abs(shiftx)) + vidWidth)\n",
    "\n",
    "    # Assume max positive shift = max negative shift; centers reference frame\n",
    "        # This was the original code but for some reason works for some but not all sets of images\n",
    "        # midindexy = (newsizey - vidHeight) / 2 + 1\n",
    "        # midindexx = (newsizex - vidWidth) / 2 + 1\n",
    "    midindexy = (newsizey - vidHeight) / 2\n",
    "    midindexx = (newsizex - vidWidth) / 2\n",
    "\n",
    "    # Determine how many images are in the output directory in case run was stopped while in progress\n",
    "    files_in_outputdir = glob.glob(os.path.join(output_dir, f\"*_dedrifted*.{output_format}\"))\n",
    "    num_files_in_outputdir = len(files_in_outputdir)\n",
    "\n",
    "    # If the 'output_dir' does not contain any images or contains the entire set of dedrifted images, it will start\n",
    "    # processing the images from the beginning.\n",
    "    # If the 'output_dir' contains some of the dedrifted images but not all from the 'input_dir', it will continue\n",
    "    # processing the images where it left off.\n",
    "    if num_files_in_outputdir == (0 or nFrames):\n",
    "        range_of_images = range(nFrames)\n",
    "    else:\n",
    "        range_of_images = range(num_files_in_outputdir, nFrames)\n",
    "\n",
    "    # The following code takes the image and shifts it according to the shift array in a frame padded with a black\n",
    "    # border if overwrite is False. Newly dedrifted images will be saved with an extra number at the end if the same\n",
    "    # file already exists in the 'output_dir'\n",
    "    for i in range_of_images:\n",
    "        frame_shift = np.zeros((newsizey, newsizex), dtype='uint8')\n",
    "\n",
    "        img = cv2.imread(images[i])\n",
    "        if img.shape[2] == 3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # For every image, want to shift the frame according to shifty/shiftx and center and pad it.\n",
    "        # starty/x and endy/x are the coordinates inside the frame_shift frame in which to place the image (img)\n",
    "        starty = (midindexy + shifty[i]).astype(int)\n",
    "        endy   = (midindexy + shifty[i] + (vidHeight)).astype(int)\n",
    "        startx = (midindexx + shiftx[i]).astype(int)\n",
    "        endx   = (midindexx + shiftx[i] + (vidWidth)).astype(int)\n",
    "        frame_shift[starty:endy, startx:endx] = img\n",
    "\n",
    "        # This file is the corrected image and is subsequently saved\n",
    "        dedrifted = np.round_(frame_shift)\n",
    "\n",
    "        # This code saves the dedrfited images into the output directory. If overwrite is False, then newly saved\n",
    "        # images will not overwrite files with the same name already in the output directory.\n",
    "        if overwrite == False:\n",
    "            a = glob.glob(os.path.join(output_dir, f\"{images[i].rsplit('.')[0]}_dedrifted*.{output_format}\"))\n",
    "            b = len(a)\n",
    "            if b == 0:\n",
    "                cv2.imwrite(os.path.join(output_dir, f\"{images[i].rsplit('.')[0]}_dedrifted.{output_format}\"), dedrifted)\n",
    "            elif b == 1:\n",
    "                cv2.imwrite(os.path.join(output_dir, f\"{images[i].rsplit('.')[0]}_dedrifted1.{output_format}\"),\n",
    "                            dedrifted)\n",
    "            else:\n",
    "                cv2.imwrite(os.path.join(output_dir, f\"{images[i].rsplit('.')[0]}_dedrifted{b}.{output_format}\"),\n",
    "                            dedrifted)\n",
    "        else:\n",
    "            cv2.imwrite(os.path.join(output_dir, f\"{images[i].rsplit('.')[0]}_dedrifted.{output_format}\"), dedrifted)\n",
    "\n",
    "    # This code will print out how many images are done to determine progress\n",
    "        if i % 50 == 0:\n",
    "            print(f'{i} frames out of {nFrames} are done')\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Call all of the functions using the main function\n",
    "def Drifty_Shifty(input_dir, output_dir, output_format,\n",
    "                  image_range_ds=True, shift_data=\"True\", pad=True, overwrite=True, parallel=True):\n",
    "\n",
    "    start = timer()\n",
    "    print(f'start shifting')\n",
    "\n",
    "    # define current working dir as cwd\n",
    "    cwd = os.curdir\n",
    "\n",
    "    # Change the working directory to the input directory\n",
    "    os.chdir(input_dir)\n",
    "\n",
    "    # Get all the individual files in the input directory\n",
    "    files = sorted(os.listdir(input_dir))\n",
    "\n",
    "    # These are all the accepted types of extensions\n",
    "    expected_ext = ['png', 'tif', 'tiff']\n",
    "\n",
    "    # Determine input format type\n",
    "    fileNames = [img for img in files if (img.split(\".\")[-1].lower() in expected_ext and img[0].isalnum())]\n",
    "\n",
    "    # in case someone accidentally inputs another type of format (ie. jpg), the output format will be tif\n",
    "    if output_format not in expected_ext:\n",
    "        output_format = 'tif'\n",
    "\n",
    "\n",
    "    # If you don't want to convert all of your images in your folder, then input a tuple of integers as image_range.\n",
    "    # Input 2 integers (bracketed and separated by a comma) to denote the start and the end of the images to be\n",
    "    # converted. If you do not input exactly 2 integers, an error will be raised. If image_range is True,\n",
    "    # all the files in the folder will be passed into the function.\n",
    "    if image_range_ds != True:\n",
    "        if len(image_range_ds)!=2:\n",
    "            sys.exit(\"image_range doesn't exist. Please input a tuple of two values.\")\n",
    "        else:\n",
    "            fileNames = fileNames[image_range_ds[0]:image_range_ds[1]]\n",
    "\n",
    "    # this code calls the functions to calculate the shift array and save it as an .npz file in the 'input_dir'.\n",
    "    # If shift_data is not True and is instead a path to an .npz file that contains the shift data, then the code\n",
    "    # will bypass this part and go directly to pad images.\n",
    "    if shift_data == \"True\":\n",
    "        fft_ref, vidHeight, vidWidth, centery, centerx = get_ref(fileNames)\n",
    "        if parallel == False:\n",
    "            # Serial processing\n",
    "            maxYX = [calc_shift(fileNames[i], fft_ref) for i in range(len(fileNames))]\n",
    "            shift_arrays = calc_shift2(fileNames, maxYX, vidHeight, vidWidth, centery, centerx)\n",
    "        else:\n",
    "            # Joblib multiprocessing\n",
    "            maxYX = Parallel(n_jobs=-1, prefer=\"threads\")(delayed(calc_shift)(fileNames[i], fft_ref)\n",
    "                                                          for i in range(len(fileNames)))\n",
    "            shift_arrays = calc_shift2(fileNames, maxYX, vidHeight, vidWidth, centery, centerx)\n",
    "\n",
    "\n",
    "        # if overwrite is False, then any previously saved shift arrays will not be overwritten and new arrays will\n",
    "        # instead have an extra number at the end.\n",
    "        if overwrite == False:\n",
    "            a = glob.glob('shift_arrays*.npz')\n",
    "            b = len(a)\n",
    "            if b == 0:\n",
    "                np.savez('shift_arrays.npz', x=shift_arrays[1], y=shift_arrays[0])\n",
    "                shift_arrays = 'shift_arrays.npz'\n",
    "            elif b == 1:\n",
    "                np.savez(f'shift_arrays1.npz', x=shift_arrays[1], y=shift_arrays[0])\n",
    "                shift_arrays = 'shift_arrays1.npz'\n",
    "            else:\n",
    "                np.savez(f'shift_arrays{b}.npz', x=shift_arrays[1], y=shift_arrays[0])\n",
    "                shift_arrays = f'shift_arrays{b}.npz'\n",
    "        else:\n",
    "            np.savez('shift_arrays.npz', x=shift_arrays[1], y=shift_arrays[0])\n",
    "            shift_arrays = 'shift_arrays.npz'\n",
    "    # but if already have a shift array for this particular set of images saved somewhere, then put that file into the\n",
    "    # input_dir and input path as argument for shift_arrays\n",
    "    else:\n",
    "        print('importing shift arrays')\n",
    "        shift_arrays = shift_data\n",
    "    end = timer()\n",
    "    print(f'elapsed time: {end - start}')\n",
    "\n",
    "    # use this function to actually shift the images in the frame with a black padding\n",
    "    if pad == True:\n",
    "        start = timer()\n",
    "        print(f'start padding')\n",
    "\n",
    "        pad_images(fileNames, shift_arrays, output_dir, output_format, overwrite)\n",
    "\n",
    "        end = timer()\n",
    "        print(f'elapsed time: {end - start}')\n",
    "\n",
    "\n",
    "    # change the working directory back to the original one\n",
    "    os.chdir(cwd)\n",
    "\n",
    "    print('dedrifting successful')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57156d1",
   "metadata": {},
   "source": [
    "# All the functions for Crop_aligned_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_black_border(images):\n",
    "    y_nonzero, x_nonzero = list(zip(*[np.nonzero(i) for i in images]))\n",
    "\n",
    "    min_y = np.max([np.min(y) for y in y_nonzero])\n",
    "    max_y = np.min([np.max(y) for y in y_nonzero])\n",
    "    min_x = np.max([np.min(x) for x in x_nonzero])\n",
    "    max_x = np.min([np.max(x) for x in x_nonzero])\n",
    "\n",
    "    return min_y, min_x, max_y, max_x\n",
    "\n",
    "\n",
    "\n",
    "def crop_aligned_images(input_dir, output_dir, output_format):\n",
    "    start = timer()\n",
    "    print('start cropping')\n",
    "\n",
    "    # define current working dir as cwd\n",
    "    cwd = os.curdir\n",
    "\n",
    "    # Change the working directory to the input directory\n",
    "    os.chdir(input_dir)\n",
    "\n",
    "    # Get all the individual files in the input directory\n",
    "    files = sorted(os.listdir(input_dir))\n",
    "\n",
    "    # These are all the accepted types of extensions\n",
    "    expected_ext = ['png', 'tif', 'tiff']\n",
    "\n",
    "    # Determine input format type\n",
    "    fileNames = [img for img in files if (img.split(\".\")[-1].lower() in expected_ext and img[0].isalnum())]\n",
    "    images = [cv2.imread(f) for f in fileNames]\n",
    "    images = [cv2.cvtColor(i, cv2.COLOR_BGR2GRAY) for i in images if i.shape[2]==3]\n",
    "    names = [f.rsplit('.')[0] for f in fileNames]\n",
    "\n",
    "    min_y, min_x, max_y, max_x = remove_black_border(images)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        image = images[i][min_y:max_y, min_x:max_x]\n",
    "        cv2.imwrite(os.path.join(output_dir, f\"{names[i]}_crop.{output_format}\"), image)\n",
    "\n",
    "    end = timer()\n",
    "    print(f'elapsed time {end-start}')\n",
    "    print('cropping successful')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d278178",
   "metadata": {},
   "source": [
    "# Main function for FocusStackerDedrifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FocusStackerDedrifter(input_dir, output_dir_fs, output_dir_ds, output_dir, output_format, fs=True,\n",
    "                           image_range_fs=True, ds=True, image_range_ds=True, shift_data=True, pad=True, overwrite=True,\n",
    "                           parallel=True, crop=True):\n",
    "\n",
    "\n",
    "    if fs == True:\n",
    "        FocusStacker(input_dir, output_dir_fs, output_format, parallel=True, image_range_fs=True,\n",
    "                     overwrite=True)\n",
    "    if ds == True:\n",
    "        Drifty_Shifty(output_dir_fs, output_dir_ds, output_format, image_range_ds=True, shift_data=True,\n",
    "                      pad=True, overwrite=True, parallel=True)\n",
    "    if crop == True:\n",
    "        crop_aligned_images(output_dir_ds, output_dir, output_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925af21a",
   "metadata": {},
   "source": [
    "# All the inputs: please refer to the introduction section and read carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328f4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Volumes/Caro2/finalstack_orig\"\n",
    "output_dir_fs = \"/Volumes/Caro2/finalstack_orig\"\n",
    "output_dir_ds = \"/Volumes/Caro2/finalstack_dedrift\"\n",
    "output_dir = \"/Volumes/Caro2/finalstack_crop\"\n",
    "output_format = 'png'\n",
    "fs=True\n",
    "image_range_fs=True\n",
    "ds=True\n",
    "image_range_ds=True\n",
    "shift_data=True\n",
    "pad=True\n",
    "overwrite=True\n",
    "parallel=True\n",
    "crop=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2300b52",
   "metadata": {},
   "source": [
    "# Call the FocusStackerDedrifter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe635f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FocusStackerDedrifter(input_dir, output_dir_fs, output_dir_ds, output_dir, output_format, fs=True,\n",
    "                           image_range_fs=True, ds=True, image_range_ds=True, shift_data=True, pad=True, \n",
    "                           overwrite=True, parallel=True, crop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FocusStackerDedrifter]",
   "language": "python",
   "name": "conda-env-FocusStackerDedrifter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
